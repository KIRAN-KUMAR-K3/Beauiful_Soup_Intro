{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beauiful_Soup_Intro (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK0oEjKN-KVs"
      },
      "source": [
        "# **The essential fundamentals of web scraping are:**\n",
        "\n",
        "\n",
        "*   To understand the basics of HTML and CSS. \n",
        "*   HTML is used to give structure for a web page and CSS beautify the webpage.\n",
        "*   To explore the web page structure and usage of developer tools.\n",
        "*   To make HTTP requests and get HTML responses.\n",
        "*   To get specific structured information using beautifulsoup.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jfu3HK075WY"
      },
      "source": [
        "# **BeautifulSoup**\n",
        "\n",
        "\n",
        "*   Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. \n",
        "*   Say you’ve found some webpages that display data relevant to your work/research, such as date or address information, but that do not provide any way of downloading the data directly. Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. \n",
        "*   It is a tool for web scraping that helps you clean up and parse the documents you have pulled down from the web.\n",
        "*   This process is suitable for static content which is available by making an HTTP request to get the webpage content\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX8oxKST-FLg"
      },
      "source": [
        "# **Basic Termes in Web Scraping**\n",
        "\n",
        "1.   **Crawler**: is a web bot that visits a stack of web pages and accumulates the links (URLs) of the nodes, deriving new URLs from each new web page [html] that it visits. Crawler might or might not get pages’ info in a data storage. It does not go deep unless programmed explicitly.\n",
        "2.   **Scraper**: is a bot that visits web pages of a given set of URLs. It does not collect new URLs (as a crawler does). It rather visits pre-collected URLs and retrieves relevant data to store into a data storage.\n",
        "3.   **Parser**: is an [offline] robot that processes or analyses given data to dervie a proper data structures. It retrieves information from [unstructured] data, whether from data storage or directly from the web (e.g. HTML).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU-kRXbO_iFn"
      },
      "source": [
        "# **Types of Parser**\n",
        "\n",
        "1.   **html.parser** :  built-in, no extra dependencies needed.\n",
        "2.   **html5lib** : the most lenient (not strictly matches your pattern), better use it if HTML is broken.\n",
        "3.   **lxml** : the fastest.\n",
        "html2text check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItZUgMaFaF83"
      },
      "source": [
        "**How to Make a Soup out of HTML File**\n",
        "\n",
        "(Note: Here Soup mean way we prase the HTML Tree)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4W3L5Q_XnG2"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('intro_to_soup_html.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "# Make soup\n",
        "# Syntax = BeautifulSoup(html_data,parser)\n",
        "# Our parser is lxml or html.parser which we have installed\n",
        "\n",
        "html_file = read_file()\n",
        "#print(html_file)\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(html_file,'lxml')\n",
        "#print(soup)\n",
        "#type(soup)\n",
        "\n",
        "# soup prettify\n",
        "#print(soup.prettify())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_qTOqPCaUA7"
      },
      "source": [
        "# **How to Make a Soup out of any Website HTML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW_qGTKpbJ0g",
        "outputId": "219c4302-d047-46f0-b978-7285cacbe51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install fake_useragent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fake_useragent in /usr/local/lib/python3.6/dist-packages (0.1.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqmM7H1lbFRe"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "ua = UserAgent()\n",
        "header = {'user-agent':ua.chrome}\n",
        "google_page = requests.get('https://www.google.com',headers=header)\n",
        "#print(google_page.content)\n",
        "\n",
        "soup = BeautifulSoup(google_page.content,'lxml') # html.parser\n",
        "\n",
        "print(soup.prettify())\n",
        "\n",
        "\n",
        "#identify some tags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-AS6aMRdNoe"
      },
      "source": [
        "# Analysis to HTML **Tags**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol4oKTohdSPl"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('tags.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "#print(soup)\n",
        "\n",
        "# Accessing tags\n",
        "meta = soup.meta\n",
        "#print(meta) # gives us the first occurance of meta tag.\n",
        "\n",
        "div = soup.div\n",
        "#print(div) # gives us the first occurance of tag ->div.\n",
        "\n",
        "# tag methods\n",
        "'''\n",
        "name\n",
        "-- attributes\n",
        ".get() method\n",
        "dictionary\n",
        "'''\n",
        "#print(\"Value of Charset via get method is: \")\n",
        "#print(meta.get(\"charset\"))\n",
        "\n",
        "#print(\"Value of Charset via  dictonary is: \")\n",
        "#print(meta[\"charset\"]) # can be treated as dictionary\n",
        "\n",
        "# modify attributes at runtime\n",
        "body = soup.body\n",
        "#print(body) # prints entire body content\n",
        "#print(body['style'])  # output will be blank as there is no style\n",
        "body['style'] = 'some style' \n",
        "#print(body['style']) # returns some style\n",
        "\n",
        "'''\n",
        " Multi valued attributes\n",
        "'''\n",
        "#print(body['class']) # here class has two attributes(list): first and second"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6SlajmAihRQ"
      },
      "source": [
        "# **Navigable Strings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqAjLpjHikkr"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('intro_to_soup_html.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "# Navigable strings in the HTML file are: Intro_to_soup, In first div, In second div\n",
        "\n",
        "# To access string inside a tag use .string method (Accessing Navigable strings )\n",
        "title = soup.title\n",
        "\n",
        "#print(title)         #Complete HTML Element is printed\n",
        "#print(title.string)  #String in the HTML element is printed\n",
        "\n",
        "\n",
        "# .replace_with(\"\") function            -- navigable string\n",
        "print(\"Before replacing:\")\n",
        "print(title)\n",
        "\n",
        "title.string.replace_with(\"title has been changed\") # replaces \"Intro_to_soup\" to \"title has been changed\"\n",
        "\n",
        "print(\"After replacing:\")\n",
        "print(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gLMNWn_9o6C"
      },
      "source": [
        "#**Navigating Through tag Names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfTMbJx_9x_O",
        "outputId": "4937a687-db1f-4fcc-a7d1-8b373fe23a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "# example  -- accessing tags directely from their tag names\n",
        "title = soup.title\n",
        "print(title) # prints 1st title tag\n",
        "\n",
        "p = soup.p\n",
        "print(p) # prints 1st p tag\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<title>\n",
            "            The Dormouse's story\n",
            "        </title>\n",
            "<p class=\"title\">\n",
            "<b>\n",
            "                The Dormouse's story\n",
            "            </b>\n",
            "</p>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6JN6V_t_lZ1"
      },
      "source": [
        "# **Navigating Through Child tag** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYdEFNb_uaC"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "# tag.contents         -- returns a list of children\n",
        "head = soup.head\n",
        "#print(head.contents)\n",
        "\n",
        "for child in head.contents:\n",
        "    #print(child if child is not None else'')\n",
        "    pass\n",
        "\n",
        "body = soup.body\n",
        "#print(body.contents)\n",
        "for child in body.contents:\n",
        "    print(child if child is not None else '', end='\\n\\n\\n\\n')  #here end='\\n\\n\\n\\n' is written only to differntiating between tags works fine if deleted\n",
        "    pass\n",
        "\n",
        "\n",
        "# .children         -- returns an iterator\n",
        "for child in body.children:\n",
        "    #print(child if child is not None else '', end='\\n\\n\\n\\n')\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTt-opaHMhpH"
      },
      "source": [
        "# Navigating with Beautifulsoup - Going Down - use three_sisters.html\n",
        "\n",
        "There are 3 types of movement across html Parse tree\n",
        "\n",
        "1.   Down the Tree - body tag to P tag\n",
        "2.   Up the Tree - P tag to body tag\n",
        "3.   Sideways Movement - P tag to P tag Movement\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXxh9RU6_0Kj"
      },
      "source": [
        "#This script describes how to move up in an html parse tree from a child tag\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "title = soup.title\n",
        "\n",
        "parent = title.parent\n",
        "#print(parent)   #prints the complete parent tag HTML Element\n",
        "#print(parent.name)   # method.name ---> gives Parent tag's name\n",
        "\n",
        "\n",
        "# .parent\n",
        "p = soup.p  \n",
        "#print(p)  #prints first occurance of p tag\n",
        "#print(p.parent) #prints complte body tag, since it is the parent of p tag\n",
        "#print(p.parent.name) # prints only the name of the parent\n",
        "\n",
        "'''\n",
        "note: all p tags are siblings in the html\n",
        "Tree starts from soup --> has its child as HTML --> HTML has childerns as head and body --> head and boby has childrens depending on the structure of web pag\n",
        "'''\n",
        "\n",
        "# html\n",
        "html = soup.html\n",
        "#print(type(html.parent))         #   bs4 (top level parent of every parse tags) ---> html ---- prints the parent of html\n",
        "\n",
        "\n",
        "# soup\n",
        "print(soup.parent) # returns none as it is at top of the hirerchey"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV9sS_XeWJhh"
      },
      "source": [
        "'''This script describes .parent method, how access all the \n",
        "parents of a perticular tag'''\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "'''\n",
        " .parents              --- returns a list (generator)  of parents\n",
        " we shall use 'a' tag\n",
        " 'a' tag has parent as 'p' tag which has parent as 'body' tag and so on\n",
        "\n",
        "#moving up the tree: a --> p --> body --> html --> beautifulsoup\n",
        "\n",
        "'''\n",
        "\n",
        "link = soup.a\n",
        "#print(link) # prints first a tag\n",
        "#print(link.parents) # returns generator object parents at mem location\n",
        "#print(link.parent) # returns P tag structure\n",
        "#print(link.parent.name) # returns a tag's parent name only\n",
        "\n",
        "for parent in link.parents:\n",
        "    print(parent.name) # p --> body --> html --> doc\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JNKez3gZC5R"
      },
      "source": [
        "# Navigating with Beautifulsoup - Going Sideway (moving through siblings) - use three_sisters.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6XSouGbZI9y",
        "outputId": "5f5e1f96-5e7c-4fcc-b239-2702b80800ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "#This script demonstrates moving from current tag to next sibling tag\n",
        "#Here we are moving side ways\n",
        "\n",
        "#observer that first b and p tags are siblings\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "body = soup.body\n",
        "p = soup.body.p\n",
        "#print(p) #print first p tag with class title\n",
        "\n",
        "# body - contents\n",
        "print(body.contents)\n",
        "\n",
        "''' .next_sibling\n",
        " our task now is to move from p tag \"title\" to next p tag \"story\".\n",
        "observe the output of print(body.contents) their is a new line character \"\\n\"\n",
        "and then the p tag \"story\"\n",
        "'''\n",
        "#print(p.next_sibling) # prints nothing as it is new line character\n",
        "#print(p.next_sibling.next_sibling) #prints p tag \"story\". Moving side ways\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', <b></b>, '\\n', <p class=\"title\">\n",
            "<b>\n",
            "                The Dormouse's story\n",
            "            </b>\n",
            "</p>, '\\n', <p class=\"story\">\n",
            "            Once upon a time there were three little sisters; and their names were\n",
            "            <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
            "                Elsie\n",
            "            </a>\n",
            "            ,\n",
            "            <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
            "                Lacie\n",
            "            </a>\n",
            "                and\n",
            "            <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link2\">\n",
            "                Tillie\n",
            "            </a>\n",
            "                ; and they lived at the bottom of a well.\n",
            "        </p>, '\\n', <p class=\"story\">\n",
            "<b>\n",
            "                The End\n",
            "            </b>\n",
            "</p>, '\\n']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' .next_sibling\\n our task now is to move from p tag \"title\" to next p tag \"story\".\\nobserve the output of print(body.contents) their is a new line character \"\\n\"\\nand then the p tag \"story\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x60u0OexcMBG"
      },
      "source": [
        "'''\n",
        "This script demonstrates moving from current tag to previous sibling tag\n",
        "Here we are moving side ways\n",
        "Here we are moving from body tag to head tag\n",
        "'''\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "\n",
        "body = soup.body\n",
        "\n",
        "# contents - html\n",
        "#print(soup.html.contents) #prints complete html\n",
        "\n",
        "#we shall move from body tag to head tag\n",
        "# .previous_sibling\n",
        "#print(body.previous_sibling) # prints nothing as it is new line character\n",
        "#print(body.previous_sibling.previous_sibling) #prints head tag, sibling of body tag, moving up or previous sibling\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkwfVFFOeOF7"
      },
      "source": [
        "'''\n",
        "This script demonstrates moving from current tag to next tag and previous sibling tag.\n",
        "Here we are moving side ways.\n",
        "Here we are moving from 'p' tag to next 'p' tag, also to previous 'b' tag siblings.\n",
        "'''\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def read_file():\n",
        "    file = open('three_sisters.html')\n",
        "    data = file.read()\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "soup = BeautifulSoup(read_file(),'lxml')\n",
        "p = (soup.body.p)\n",
        "#print(p)   #prints first 'p' tag. <p class=\"title\">\n",
        "\n",
        "\n",
        "# .next_siblings (after b tag it has two siblings i.e, p, p tags)\n",
        "#Use inline if to escape the '\\n': (value if contiditon else '')\n",
        "\n",
        "for sibling in p.next_siblings:\n",
        "  #print(sibling.name if sibling != '\\n' else '') # note: here we are omitting new line character see tree\n",
        "  pass\n",
        "\n",
        "\n",
        "# .previous_siblings (before first 'p' tag there is only one 'b' tag) # note: here we are omitting new line character see tree\n",
        "\n",
        "for sibling in p.previous_siblings:\n",
        "  print(sibling if sibling  != '\\n' else '') \n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}